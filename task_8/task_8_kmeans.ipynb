{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94068cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "\n",
    "import cv2\n",
    "\n",
    "import sys\n",
    "sys.path.append('/workspaces/dbm25/task_1_2')\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "from extract_features import extract_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36aa4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample image path\n",
    "sample_image_path = '/workspaces/dbm25/data/Part2/Part2/brain_glioma/brain_glioma_1003.jpg'\n",
    "# Load gray scale image with cv2\n",
    "image = cv2.imread(sample_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "rgb   = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64143f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42e0a6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-19 14:17:00.684110: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-19 14:17:00.685406: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-19 14:17:00.689776: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-19 14:17:00.699436: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1747664220.715436     613 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1747664220.720029     613 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1747664220.732526     613 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747664220.732549     613 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747664220.732552     613 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1747664220.732553     613 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-19 14:17:00.737472: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "You are using a model of type vitxrs to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at /workspaces/dbm25/data/vit_b16_224-mluke/vision_encoder and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last_hidden_state: torch.Size([1, 197, 768])\n",
      "pooler_output: torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import ViTConfig, ViTModel, ViTImageProcessor\n",
    "\n",
    "# 1. Load the ViT config from your local folder\n",
    "vision_config = ViTConfig.from_pretrained(\n",
    "    \"/workspaces/dbm25/data/vit_b16_224-mluke/vision_encoder\"\n",
    ")\n",
    "\n",
    "# 2. Load the model weights into a ViTModel\n",
    "vision_model = ViTModel.from_pretrained(\n",
    "    \"/workspaces/dbm25/data/vit_b16_224-mluke/vision_encoder\",\n",
    "    config=vision_config,\n",
    "    # map_location=\"cpu\",  # uncomment if you need CPU-only\n",
    ")\n",
    "\n",
    "# 3. Set to eval mode if youâ€™re doing inference\n",
    "vision_model.eval()\n",
    "\n",
    "# 4. Prepare your images for ViT\n",
    "processor = ViTImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
    "# If you have PIL images in a list called `images`:\n",
    "inputs = processor(images=rgb, return_tensors=\"pt\")\n",
    "\n",
    "outputs   = vision_model(**inputs)\n",
    "# Print the keys of the output and their shapes\n",
    "for key, value in outputs.items():\n",
    "    print(f\"{key}: {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "815ab9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature dictionary from /workspaces/dbm25/data/extracted_features.pt\n",
    "feature_list = torch.load('/workspaces/dbm25/data/extracted_features.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99f779bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['file_path', 'class', 'cm', 'hog', 'avgpool', 'layer3', 'fc'])\n"
     ]
    }
   ],
   "source": [
    "print(feature_list[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97cec734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_path': '/workspaces/dbm25/data/Part1/Part1/brain_glioma/brain_glioma_0051.jpg', 'class': 'brain_glioma', 'cm': tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  3.3333e-03,\n",
      "         3.3222e-03,  1.7234e+01,  4.6667e-02,  7.7822e-02,  7.1705e+00,\n",
      "         2.3333e-02,  3.6122e-02,  8.8549e+00,  5.3333e-02,  7.7156e-02,\n",
      "         5.6383e+00,  5.0000e-02,  6.7500e-02,  5.6880e+00,  4.3333e-02,\n",
      "         4.1456e-02,  4.4858e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         1.8467e+00,  7.2098e+00,  3.2567e+00,  2.6333e+00,  3.5589e+00,\n",
      "         3.3027e-01,  1.7380e+01,  1.1373e+03,  2.5840e+00,  4.6560e+01,\n",
      "         2.3561e+03,  1.0891e+00,  6.5000e+01,  2.2524e+03,  6.9589e-01,\n",
      "         6.6523e+01,  1.8115e+03,  8.6714e-01,  5.6347e+01,  3.1201e+03,\n",
      "         9.5670e-01,  1.5770e+01,  1.5331e+03,  2.9974e+00,  1.9967e+00,\n",
      "         2.1567e+00,  4.5398e+00,  6.0667e-01,  3.6529e-01,  4.4642e-01,\n",
      "         2.1700e+00,  9.4110e-01, -3.4489e-01,  3.1687e+01,  1.5486e+03,\n",
      "         1.1615e+00,  5.9967e+01,  6.6456e+02,  9.7020e-01,  5.4143e+01,\n",
      "         1.3052e+02,  1.0960e+00,  5.7713e+01,  3.3511e+01,  1.2850e+00,\n",
      "         5.7790e+01,  3.3453e+01,  3.8391e+00,  5.5973e+01,  7.5299e+01,\n",
      "        -3.4653e+00,  6.2113e+01,  2.2686e+03,  9.3702e-01,  1.5937e+01,\n",
      "         1.3064e+03,  2.7579e+00,  6.8000e-01,  3.5093e-01,  4.3130e-01,\n",
      "         1.5690e+01,  1.2665e+03,  2.6729e+00,  5.1330e+01,  4.4541e+02,\n",
      "         1.4953e+00,  5.4260e+01,  1.5113e+02,  1.0670e+00,  6.3607e+01,\n",
      "         1.2845e+02,  1.5307e+00,  6.1047e+01,  2.1318e+01,  1.7619e-01,\n",
      "         6.0007e+01,  1.5927e+02,  3.4039e+00,  5.9663e+01,  2.4468e+02,\n",
      "         3.4429e+00,  5.5660e+01,  3.0384e+01,  1.9051e+00,  4.6803e+01,\n",
      "         1.7864e+03,  6.8736e-01,  1.0333e+00,  8.4556e-01, -1.4481e-02,\n",
      "         3.7420e+01,  2.8503e+03,  1.4936e+00,  6.7303e+01,  8.1298e+02,\n",
      "         5.5745e-01,  7.0860e+01,  1.3124e+03,  6.4829e-01,  6.3087e+01,\n",
      "         1.0070e+03,  1.5095e+00,  6.3377e+01,  5.5791e+02,  2.1107e+00,\n",
      "         8.0007e+01,  1.5742e+03,  1.6025e+00,  5.7237e+01,  1.7117e+02,\n",
      "         1.5816e+00,  5.5267e+01,  3.4429e+01,  1.1289e+00,  6.8083e+01,\n",
      "         2.1400e+03,  3.5978e-01,  1.2033e+00,  9.2866e-01, -1.9170e-01,\n",
      "         4.1930e+01,  2.9232e+03,  1.1836e+00,  4.1250e+01,  2.2920e+02,\n",
      "         9.0936e-01,  6.1747e+01,  6.6723e+02,  1.6949e+00,  5.4893e+01,\n",
      "         1.5088e+02,  5.6007e-01,  5.6753e+01,  2.0017e+02,  2.4929e+00,\n",
      "         6.4677e+01,  3.5201e+02,  1.6409e+00,  5.5030e+01,  3.0230e+02,\n",
      "         1.1054e+00,  5.3950e+01,  3.9641e+01,  1.7801e+00,  4.9467e+01,\n",
      "         1.3935e+03,  2.5180e-01,  1.3500e+00,  8.2750e-01, -7.4626e-01,\n",
      "         1.5160e+01,  1.3209e+03,  2.9747e+00,  5.2920e+01,  5.4865e+02,\n",
      "         1.2482e+00,  5.2233e+01,  1.3332e+01, -9.2382e-01,  5.6093e+01,\n",
      "         2.4491e+01,  1.4809e+00,  5.7273e+01,  1.5939e+01,  4.5862e-01,\n",
      "         5.7250e+01,  7.4654e+01,  1.5201e+00,  5.2147e+01,  9.0018e+01,\n",
      "        -1.9221e+00,  5.5617e+01,  8.1999e+02,  8.9825e-01,  2.6630e+01,\n",
      "         1.6040e+03,  1.4525e+00,  9.5333e-01,  5.7782e-01,  7.8160e-02,\n",
      "         1.5567e+00,  1.3335e+00,  2.5802e-01,  3.6300e+01,  2.5273e+03,\n",
      "         1.3145e+00,  6.8267e+01,  1.6072e+03,  7.6944e-01,  5.5157e+01,\n",
      "         5.3793e+02,  1.0243e+00,  5.1717e+01,  2.6795e+02, -1.1075e+00,\n",
      "         5.1197e+01,  3.5035e+02, -1.5965e-01,  6.7487e+01,  1.8830e+03,\n",
      "         8.3543e-01,  4.2477e+01,  2.9095e+03,  9.9693e-01,  1.9500e+00,\n",
      "         3.3075e+00,  2.7973e+00,  7.1667e-01,  2.0972e-01, -8.5716e-01,\n",
      "         9.8667e-01,  3.3065e+00,  3.5591e+00,  1.5700e+00,  3.2451e+00,\n",
      "         1.4157e+00,  3.9633e+00,  1.8189e+02,  6.9282e+00,  2.7147e+01,\n",
      "         2.3157e+03,  1.8062e+00,  4.1733e+01,  3.1268e+03,  1.2436e+00,\n",
      "         3.9540e+01,  2.9786e+03,  1.2468e+00,  9.5467e+00,  6.2880e+02,\n",
      "         3.1564e+00,  1.2467e+00,  1.7992e+00,  6.9627e-01,  1.2033e+00,\n",
      "         2.1087e+00,  1.0152e+00,  3.0333e-01,  2.1132e-01,  8.5563e-01,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]), 'hog': tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.0000e+00, 2.8913e+01, 3.5521e+01, 3.6056e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2361e+00, 1.8754e+01, 1.1573e+03,\n",
      "        1.0000e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.4738e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.4810e+01, 5.8374e+02, 8.0836e+02,\n",
      "        3.2310e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 4.7351e+02, 1.2026e+03, 1.5453e+02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7370e+03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 4.7798e+02, 1.0562e+03, 3.3423e+02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9241e+03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.2361e+00, 2.5947e+02, 1.0657e+01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9000e+01,\n",
      "        2.8284e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.0708e+01, 0.0000e+00, 4.5202e+02, 1.4142e+00, 1.0000e+00, 0.0000e+00,\n",
      "        4.1623e+00, 0.0000e+00, 0.0000e+00, 2.1205e+02, 3.2033e+02, 8.8626e+02,\n",
      "        2.1268e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.4514e+02, 1.4299e+03, 4.8826e+01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7245e+01, 5.4976e+02,\n",
      "        2.5456e+01, 0.0000e+00, 7.2111e+00, 1.0436e+03, 2.1616e+01, 0.0000e+00,\n",
      "        1.2325e+01, 9.5366e+00, 1.2661e+02, 4.2426e+00, 0.0000e+00, 4.4736e+01,\n",
      "        9.1528e+01, 5.3238e+01, 1.0198e+01, 0.0000e+00, 2.0484e+01, 7.4620e+01,\n",
      "        2.1322e+01, 6.1623e+00, 6.7082e+00, 7.4774e+01, 3.0734e+01, 2.2289e+01,\n",
      "        0.0000e+00, 0.0000e+00, 5.7938e+02, 0.0000e+00, 0.0000e+00, 2.6414e+01,\n",
      "        1.1854e+03, 4.9729e+01, 0.0000e+00, 2.0371e+02, 4.7544e+02, 7.1451e+02,\n",
      "        4.5916e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 4.1231e+00, 1.3398e+03, 1.6361e+02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1000e+01,\n",
      "        0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        2.5253e+02, 7.0505e+01, 7.9514e+02, 6.0745e+01, 0.0000e+00, 0.0000e+00,\n",
      "        2.2361e+00, 0.0000e+00, 0.0000e+00, 1.4668e+02, 1.8550e+02, 7.4114e+02,\n",
      "        2.7890e+02, 0.0000e+00, 0.0000e+00, 1.1074e+02, 2.5080e+01, 0.0000e+00,\n",
      "        0.0000e+00, 4.1000e+01, 9.3939e+02, 0.0000e+00, 0.0000e+00, 5.0000e+00,\n",
      "        4.0068e+01, 1.1710e+01, 6.7082e+00, 5.8310e+00, 6.7082e+00, 6.4389e+02,\n",
      "        0.0000e+00, 4.1231e+00, 8.6594e+00, 1.6258e+02, 6.6429e+01, 5.0990e+00,\n",
      "        5.0000e+00, 1.1314e+01, 1.1145e+02, 0.0000e+00, 1.0062e+01, 1.3462e+01,\n",
      "        1.6424e+02, 6.3192e+01, 0.0000e+00, 2.0113e+01, 1.4954e+02, 1.2831e+02,\n",
      "        7.2111e+00, 4.0378e+01, 6.1678e+01, 5.3064e+01, 1.0440e+01, 7.8102e+00,\n",
      "        1.5250e+01, 1.4142e+00, 3.5428e+01, 2.2361e+00, 1.7781e+02, 6.6343e+01,\n",
      "        3.6944e+01, 8.0179e+01, 2.1197e+02, 0.0000e+00, 0.0000e+00, 4.3320e+02,\n",
      "        0.0000e+00, 2.0000e+00, 0.0000e+00, 6.9944e+02, 3.6056e+00, 0.0000e+00,\n",
      "        3.1192e+02, 1.5444e+02, 1.4810e+03, 1.9738e+02, 1.6987e+02, 0.0000e+00,\n",
      "        5.0121e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.0236e+01,\n",
      "        2.2361e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.7632e+01, 5.5831e+02, 1.8695e+02, 3.1960e+02, 0.0000e+00, 3.1647e+01,\n",
      "        7.5216e+01, 8.8391e+01, 1.4142e+01, 0.0000e+00, 7.8102e+00, 5.1220e+01,\n",
      "        3.5000e+01, 8.5453e+01, 6.4883e+01, 1.2131e+02, 2.7753e+02, 5.9401e+01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.7679e+01, 1.1983e+02,\n",
      "        6.4737e+01, 7.9765e+01, 2.6026e+02, 4.1231e+00, 0.0000e+00, 0.0000e+00,\n",
      "        3.9072e+01, 1.3979e+02, 5.9052e+01, 2.2232e+02, 4.4348e+01, 3.5893e+01,\n",
      "        0.0000e+00, 6.3246e+00, 1.6083e+01, 0.0000e+00, 4.1561e+01, 2.1708e+01,\n",
      "        2.7016e+02, 5.7590e+01, 1.0878e+02, 8.5340e+01, 0.0000e+00, 2.4587e+01,\n",
      "        1.1555e+02, 1.9694e+02, 1.7208e+01, 1.8413e+01, 0.0000e+00, 1.8693e+02,\n",
      "        3.8490e+01, 1.6492e+01, 5.8437e+01, 1.9765e+01, 1.9547e+01, 5.0000e+00,\n",
      "        4.1943e+02, 1.4142e+00, 3.2019e+01, 1.1595e+01, 0.0000e+00, 2.0000e+00,\n",
      "        8.0623e+00, 2.5154e+01, 1.1683e+01, 9.9821e+01, 1.0198e+01, 2.4806e+01,\n",
      "        4.6095e+02, 5.3852e+01, 7.6551e+01, 1.5609e+02, 3.8857e+02, 6.7209e+01,\n",
      "        3.1853e+02, 3.6902e+01, 6.4349e+01, 2.0000e+00, 0.0000e+00, 2.2361e+00,\n",
      "        3.6503e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        4.6046e+01, 0.0000e+00, 3.2594e+02, 0.0000e+00, 2.0000e+00, 2.8146e+02,\n",
      "        4.2194e+02, 1.4942e+02, 3.7349e+02, 3.1623e+00, 5.2273e+01, 8.1394e+01,\n",
      "        0.0000e+00, 0.0000e+00, 6.4872e+01, 7.7268e+02, 1.6971e+01, 9.0808e+01,\n",
      "        1.5482e+01, 1.0973e+01, 2.7741e+01, 1.1402e+01, 0.0000e+00, 0.0000e+00,\n",
      "        7.8709e+02, 9.0341e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1038e+02,\n",
      "        3.0233e+01, 1.5180e+01, 2.8284e+00, 4.8282e+02, 1.0689e+02, 3.1623e+00,\n",
      "        3.5848e+01, 7.5575e+01, 9.8388e+01, 1.5000e+01, 0.0000e+00, 3.1017e+01,\n",
      "        6.4778e+01, 5.1371e+01, 2.1751e+01, 4.1623e+00, 2.2361e+00, 4.3916e+01,\n",
      "        9.3964e+01, 2.7003e+01, 0.0000e+00, 1.4751e+02, 1.4820e+02, 3.6056e+00,\n",
      "        6.0000e+00, 8.5611e+01, 1.3599e+02, 2.3078e+01, 1.9236e+01, 1.0646e+01,\n",
      "        6.0000e+00, 2.5756e+01, 2.9277e+01, 1.5869e+01, 0.0000e+00, 6.5844e+01,\n",
      "        0.0000e+00, 1.5342e+01, 4.1063e+01, 3.0451e+02, 0.0000e+00, 1.8000e+01,\n",
      "        7.4007e+01, 1.5955e+02, 2.3821e+02, 0.0000e+00, 0.0000e+00, 1.1928e+02,\n",
      "        1.2578e+03, 0.0000e+00, 1.6168e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.0000e+00, 2.2361e+00, 1.9000e+01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        9.4818e+02, 3.8242e+02, 4.4721e+00, 0.0000e+00, 0.0000e+00, 7.5213e+02,\n",
      "        0.0000e+00, 1.5051e+02, 1.5732e+02, 3.0003e+02, 3.0900e+02, 0.0000e+00,\n",
      "        0.0000e+00, 3.3360e+01, 9.9655e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        4.1231e+00, 6.4031e+00, 0.0000e+00, 0.0000e+00, 4.5370e+01, 1.9695e+02,\n",
      "        0.0000e+00, 4.1231e+00, 0.0000e+00, 4.2305e+02, 5.8310e+00, 0.0000e+00,\n",
      "        3.1623e+00, 3.6056e+00, 2.1792e+02, 1.7060e+01, 3.1623e+00, 0.0000e+00,\n",
      "        7.0772e+01, 3.1953e+01, 0.0000e+00, 7.8310e+00, 2.2361e+00, 1.0312e+02,\n",
      "        1.4142e+00, 7.3246e+00, 7.0711e+00, 1.1816e+02, 3.5750e+01, 0.0000e+00,\n",
      "        0.0000e+00, 5.8310e+00, 8.0567e+02, 0.0000e+00, 2.0000e+00, 0.0000e+00,\n",
      "        3.3931e+02, 8.2462e+00, 0.0000e+00, 0.0000e+00, 1.2042e+01, 8.1867e+02,\n",
      "        0.0000e+00, 0.0000e+00, 1.1767e+02, 5.3314e+02, 8.9334e+01, 9.3814e+01,\n",
      "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2168e+02,\n",
      "        1.0400e+03, 0.0000e+00, 1.7351e+02, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
      "        0.0000e+00, 1.0000e+00, 6.4787e+00, 1.4000e+01, 2.8284e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2361e+00,\n",
      "        4.6607e+02, 1.4009e+01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.3832e+02, 8.6219e+02, 3.6459e+02, 1.4700e+02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9458e+02,\n",
      "        9.8386e+02, 4.0647e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.8112e+02, 1.1117e+03, 3.2262e+02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.3772e+03, 1.6790e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3586e+03, 2.1663e+02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3095e+02,\n",
      "        1.0172e+03, 4.0961e+02, 3.4265e+02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.7577e+02, 9.9802e+02, 1.2958e+02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.4142e+00,\n",
      "        1.0950e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.0000e+00, 0.0000e+00, 2.2000e+01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.6056e+00,\n",
      "        3.7236e+01, 1.1180e+01, 3.6056e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2414e+03, 2.4631e+01, 6.4031e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        2.4662e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3828e+03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.6942e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7368e+03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00,\n",
      "        2.1478e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6124e+03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.4853e+00,\n",
      "        8.9073e+01, 2.8284e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2000e+01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "       dtype=torch.float64), 'avgpool': tensor([0.8356, 0.1613, 0.5870,  ..., 0.1757, 0.3347, 0.7882]), 'layer3': tensor([0.1084, 0.0177, 0.0076,  ..., 0.0449, 0.0102, 0.0074]), 'fc': tensor([-1.8509e-01,  2.3174e+00, -9.6069e-01,  2.0486e-01, -1.7053e-01,\n",
      "         1.2242e+00, -1.5588e+00, -3.0016e+00, -3.3217e+00, -3.1558e+00,\n",
      "        -8.6056e-01, -2.5800e+00, -2.8226e+00, -2.8008e+00, -2.4456e+00,\n",
      "        -1.8408e+00, -2.3583e+00, -3.6950e+00, -2.8799e+00, -2.0399e+00,\n",
      "        -1.7825e+00, -1.0546e+00, -1.2670e+00, -2.7060e+00, -2.4905e+00,\n",
      "         5.5744e-01,  3.4928e+00,  1.5392e+00,  1.1006e+00,  1.1614e+00,\n",
      "        -5.7153e-01, -2.7844e+00, -2.0115e-01,  2.1251e+00,  3.6337e+00,\n",
      "         9.3718e-01,  5.2600e-01, -2.4754e+00,  1.3379e+00, -3.1781e+00,\n",
      "        -1.6352e+00,  9.4429e-02, -3.0548e+00, -1.3123e+00,  6.6414e-01,\n",
      "        -4.8625e-01, -3.4554e+00,  3.8585e-01, -1.9146e+00, -1.7045e+00,\n",
      "        -7.5480e-01, -1.4092e+00,  3.8156e+00,  1.1342e+00,  8.7291e-01,\n",
      "        -1.6729e+00, -1.5056e+00,  7.0094e-01,  3.0446e+00,  2.3005e+00,\n",
      "         2.9552e+00, -7.4311e-01,  1.1722e+00,  1.8933e+00,  7.5672e-01,\n",
      "         3.4561e+00,  2.3034e+00, -4.7132e-01,  2.1804e+00,  2.6838e+00,\n",
      "        -2.0366e+00,  2.6052e+00, -1.9759e+00,  1.2873e+00, -2.8511e+00,\n",
      "         1.7155e+00,  9.2874e-02,  8.9408e-01,  5.0148e+00,  2.4876e+00,\n",
      "        -1.1066e+00, -2.6605e+00, -3.2099e+00, -3.2175e+00, -3.9408e+00,\n",
      "        -3.3419e+00, -2.4067e+00,  2.0607e-02, -9.6622e-01, -2.1152e+00,\n",
      "        -3.4636e+00, -1.5498e+00, -1.3076e+00, -2.9052e+00, -1.6673e+00,\n",
      "        -1.7428e+00, -1.7566e+00, -4.6078e+00, -1.6322e+00, -2.6493e+00,\n",
      "        -3.4370e-01, -1.1307e+00, -2.5084e+00,  1.6491e+00, -2.9837e+00,\n",
      "        -4.1544e+00, -7.6050e-01,  5.9763e+00,  1.4306e-01, -3.0585e-01,\n",
      "         2.1316e+00,  1.2467e+01, -1.1223e+00,  3.1418e-01,  3.5223e-01,\n",
      "        -7.9822e-01,  3.3576e+00,  3.3405e+00, -1.1028e+00, -1.6959e+00,\n",
      "         4.6343e-02, -2.3758e+00,  1.1897e+00, -8.8188e-01,  1.5756e-01,\n",
      "        -1.5002e+00,  4.7549e+00, -1.7839e+00, -1.2732e+00, -2.1761e+00,\n",
      "        -1.2805e+00, -3.0629e+00, -2.0200e+00, -2.2467e+00, -4.0678e+00,\n",
      "        -2.4302e+00, -1.9460e+00, -2.6955e+00, -4.5496e+00, -3.4613e+00,\n",
      "        -2.5135e+00, -2.5167e+00, -2.9836e+00, -3.3037e+00, -3.4108e+00,\n",
      "        -2.7433e+00, -2.5206e+00,  1.2691e+00, -9.1362e-01,  4.6471e-01,\n",
      "        -1.3237e+00, -1.3804e+00, -4.1130e-01, -1.1260e+00, -8.0110e-01,\n",
      "        -7.7066e-01, -1.9840e+00, -1.9443e+00, -2.1562e+00, -1.7357e+00,\n",
      "        -1.7604e+00, -2.9411e+00, -4.0262e+00, -2.1363e-01, -2.3374e+00,\n",
      "        -2.7981e+00, -3.1313e+00, -3.1445e+00, -2.4512e+00, -1.7981e+00,\n",
      "        -2.8738e+00, -3.2905e+00, -2.7812e+00, -1.5292e+00, -2.9544e+00,\n",
      "        -3.7225e+00, -3.2443e+00, -1.7641e+00, -3.3661e+00, -1.5684e+00,\n",
      "        -3.0513e+00, -5.6376e-01, -3.5144e+00, -1.7690e+00, -3.2783e+00,\n",
      "        -2.4913e+00, -2.3714e+00, -1.8550e+00, -1.0903e+00, -1.1020e+00,\n",
      "        -4.0467e-01, -2.3240e+00, -2.5728e+00, -3.0514e+00, -2.2049e+00,\n",
      "        -1.6519e+00, -2.7663e+00, -3.5518e+00, -2.9606e+00, -1.3811e+00,\n",
      "        -1.9164e+00, -5.0272e+00, -2.9205e+00, -1.4640e+00, -3.6311e+00,\n",
      "        -3.2730e+00, -3.3000e-01, -1.8326e+00, -2.2006e+00, -9.0213e-01,\n",
      "        -2.8443e+00, -2.1387e+00, -3.9940e+00, -2.3281e+00, -2.7422e+00,\n",
      "        -2.2161e+00, -2.5339e+00, -2.9489e+00, -2.8601e+00, -3.0334e+00,\n",
      "        -1.4516e+00, -2.3609e+00, -7.7314e-01, -1.5051e+00, -1.1485e-01,\n",
      "        -1.1290e+00, -2.1739e+00, -2.3235e+00, -2.0053e+00, -2.1580e+00,\n",
      "        -3.5080e+00, -1.7249e+00, -1.4431e+00, -3.2480e-01, -1.5011e+00,\n",
      "        -1.6668e+00, -3.4975e+00, -1.4818e+00, -2.0740e+00, -1.2986e+00,\n",
      "        -1.1945e+00, -1.4125e+00, -1.6318e+00, -8.9438e-01, -3.3305e+00,\n",
      "        -1.0093e+00, -3.1876e+00, -2.3297e+00, -2.7482e+00, -3.3513e+00,\n",
      "        -1.7147e+00, -2.7634e+00, -6.6941e-01, -1.6551e+00, -1.1822e+00,\n",
      "        -2.3106e+00, -9.6408e-01, -2.6330e+00, -8.6179e-01, -1.5319e+00,\n",
      "        -7.9206e-01, -2.7870e+00, -1.9037e+00, -1.4805e+00, -1.8749e+00,\n",
      "        -2.0856e+00, -2.4014e+00, -3.3779e+00, -2.6940e+00, -2.8852e+00,\n",
      "        -8.2337e-01, -1.6308e+00, -2.0346e+00, -3.3238e-01, -1.5827e-01,\n",
      "        -4.1350e-01, -1.0196e+00,  1.1930e-01, -8.8576e-01, -1.1013e-01,\n",
      "         3.0046e-01, -7.8980e-01, -3.4115e-01,  6.9253e-01, -1.4480e+00,\n",
      "        -1.3934e+00, -3.2311e+00, -3.5767e+00, -2.6956e+00, -3.1590e+00,\n",
      "        -3.8544e+00, -2.5318e+00, -2.5967e+00, -4.0348e+00, -3.0125e+00,\n",
      "        -3.0293e+00, -1.8963e+00, -1.6737e+00, -9.3996e-01, -1.0827e+00,\n",
      "        -1.8242e+00, -1.0036e+00,  1.2536e+00, -8.4828e-01, -1.4953e+00,\n",
      "        -9.5453e-01, -1.6653e-01, -2.0282e+00, -1.3602e+00, -2.1572e+00,\n",
      "         1.4680e+00, -1.4340e+00, -1.0678e+00,  8.8811e-01,  2.1986e+00,\n",
      "        -3.9926e-01, -1.2542e+00, -7.6293e-01,  2.8565e+00,  3.3554e-01,\n",
      "         6.3055e-02, -3.2586e+00, -1.2271e+00, -2.4020e+00, -1.2177e+00,\n",
      "        -2.9185e-02,  1.1534e+00,  5.5078e-01, -9.8322e-01,  8.8327e-01,\n",
      "        -3.0228e-01,  8.3077e-01, -4.2112e-01, -4.1551e-02, -1.6464e+00,\n",
      "        -2.2115e+00, -1.6410e+00, -5.7514e-01, -9.2125e-01, -1.2976e+00,\n",
      "        -2.1355e+00, -1.7223e+00, -2.7045e+00, -3.6103e+00, -3.4196e+00,\n",
      "        -4.3539e-03, -1.4835e+00, -2.0142e+00, -2.8891e+00, -2.5100e+00,\n",
      "        -5.5862e-01, -2.6288e+00, -2.8332e+00, -1.6384e+00, -2.7355e+00,\n",
      "        -3.3239e+00,  9.0941e-01,  4.9909e-01,  1.8837e+00,  1.0613e+00,\n",
      "        -2.1751e+00,  3.0196e+00,  8.8711e-01, -1.0516e+00, -1.2753e+00,\n",
      "        -2.6302e+00, -3.1862e+00, -1.0063e+00, -2.0454e+00, -3.1762e+00,\n",
      "        -2.6898e+00, -1.1334e+00, -4.0319e+00, -1.8891e+00, -2.2471e+00,\n",
      "        -2.3024e+00, -1.2640e+00, -3.4324e-01, -1.5965e+00, -2.5523e+00,\n",
      "        -1.7138e-01, -1.8268e+00, -1.5950e+00, -3.9739e+00, -5.1124e-01,\n",
      "        -1.4828e+00, -2.1828e+00, -1.8346e+00, -3.9652e+00,  1.4240e+00,\n",
      "         1.9936e+00, -1.1521e+00, -1.1441e-01, -2.6819e+00,  1.4449e+00,\n",
      "         1.1213e+00, -1.9348e+00, -3.1791e+00,  9.8560e-01,  2.1793e+00,\n",
      "         5.3911e-01, -3.7579e-02,  1.9743e+00, -8.2199e-01,  3.9150e-01,\n",
      "         2.9505e+00,  1.6538e-01, -1.5551e+00, -1.6645e+00,  7.3571e+00,\n",
      "        -2.7742e+00, -2.5790e+00,  2.7870e+00,  8.2180e-01,  6.4582e-01,\n",
      "        -1.2380e+00,  1.2224e+00,  1.4588e+00,  3.2162e+00,  2.6890e+00,\n",
      "         8.5386e-01, -1.2103e-01,  5.7076e+00,  2.1793e-01, -6.0506e-01,\n",
      "        -2.3826e+00,  3.5104e+00,  2.5044e+00,  1.5725e+00,  7.9813e-01,\n",
      "         1.4683e+00,  5.6473e-01,  1.2651e+00,  1.0514e+00, -7.1460e-01,\n",
      "         5.8701e-01, -7.1205e-01, -7.8137e-01,  7.0550e+00,  1.8256e+00,\n",
      "         1.8381e+00,  4.4782e+00,  1.6325e+00,  1.4746e+00,  7.8679e-01,\n",
      "        -7.5169e-01,  2.8928e+00,  1.7445e+00, -1.6290e+00, -2.2232e+00,\n",
      "        -2.6286e+00,  4.4358e+00, -1.3975e+00, -1.7314e+00, -3.0788e+00,\n",
      "         4.4718e+00,  2.1887e+00,  1.4294e-01, -6.9488e-01,  2.4427e+00,\n",
      "        -2.3507e+00,  2.7453e+00,  1.2412e+00,  3.4334e+00,  5.5666e+00,\n",
      "         9.9749e-01, -1.2444e+00, -3.1145e+00, -8.5722e-01,  4.3738e+00,\n",
      "         5.6471e+00,  1.9388e+00, -7.0488e-01,  4.1717e+00, -3.0009e+00,\n",
      "         2.6517e+00, -1.9933e+00,  1.6705e+00,  4.6077e-01,  3.0528e+00,\n",
      "         2.2423e-01,  2.6441e+00,  1.3515e+00, -2.4941e+00, -2.7706e+00,\n",
      "         1.8705e+00, -8.2909e-01,  2.5284e+00,  3.6110e+00, -2.9134e+00,\n",
      "         1.2682e+00, -8.2131e-01,  7.7668e-01, -2.7664e-01,  3.7833e+00,\n",
      "        -1.2811e+00, -2.2857e+00, -1.1467e+00,  1.0494e+00,  1.9473e+00,\n",
      "        -2.2571e+00,  4.7275e-01,  8.0069e-01,  2.4827e+00,  1.8523e+00,\n",
      "         1.0938e+00,  4.7067e-01,  4.3909e+00,  2.3146e+00, -1.6831e+00,\n",
      "        -2.1183e+00, -7.8347e-01,  4.0761e+00,  1.6524e+00,  2.2513e+00,\n",
      "        -1.1000e+00, -9.4583e-03, -4.1503e-01,  3.8060e+00,  2.1544e-01,\n",
      "        -2.5653e+00,  3.1099e-01,  1.3379e+00,  1.1201e+00,  1.3447e+00,\n",
      "        -2.5757e+00,  3.9300e-01,  1.2516e+00,  1.3099e+00, -1.0129e+00,\n",
      "         2.2776e+00,  1.3751e+00, -6.6153e-01, -1.0215e+00,  1.5723e+00,\n",
      "         1.4063e+00, -1.8183e+00, -2.8090e+00,  1.0718e+00,  1.3273e+00,\n",
      "         1.3501e+00,  3.1231e+00,  2.6666e+00,  4.3181e+00,  2.1433e+00,\n",
      "         2.1990e+00,  4.0491e-01, -2.7034e+00, -3.3867e+00,  2.2960e+00,\n",
      "         7.6660e-02,  6.2001e+00,  1.4459e+00,  1.5716e+00, -4.1349e-01,\n",
      "         5.9967e-01,  2.5023e+00, -9.0249e-01, -1.6475e-01,  1.0497e+00,\n",
      "        -7.8527e-01, -8.4812e-01,  1.0890e-02,  1.7693e+00, -2.8167e+00,\n",
      "        -1.3955e+00,  2.8122e+00,  2.9362e+00, -1.3721e+00, -2.5902e+00,\n",
      "         2.9425e+00,  4.0911e-01,  3.6708e+00, -7.1704e-01,  3.3734e+00,\n",
      "        -6.1013e-01, -9.7594e-01,  4.9795e+00, -2.7904e-01, -2.0993e+00,\n",
      "        -2.0005e+00,  1.9279e+00, -2.9213e+00,  2.2235e+00,  4.7716e+00,\n",
      "         1.5575e+00,  1.4976e+00,  3.0231e+00,  8.3993e-01,  8.6526e-01,\n",
      "         1.8996e+00,  2.0253e+00,  5.5705e-01,  2.1023e+00,  1.6587e+00,\n",
      "        -2.5347e+00,  2.9663e+00,  9.3356e-01, -1.6063e+00,  1.0603e+00,\n",
      "         3.4851e+00,  1.6432e+00, -2.8912e-01, -1.8245e+00,  4.5201e+00,\n",
      "         1.7779e+00,  2.3681e+00,  7.5830e-01,  8.5426e-01, -1.2372e+00,\n",
      "         3.3762e+00,  4.3542e-01,  1.5316e+00,  1.6748e+00, -2.1808e+00,\n",
      "         4.0029e+00,  1.4540e+00,  7.9111e-01,  4.5223e+00,  2.3162e+00,\n",
      "         1.7166e+00, -1.9770e+00,  3.4175e+00,  3.8760e+00, -1.3688e+00,\n",
      "        -1.9942e+00,  3.5698e+00,  2.2901e-01, -6.7758e-01,  4.5913e+00,\n",
      "         7.5718e-01,  1.8100e+00,  1.9635e+00,  4.0393e+00, -9.1008e-01,\n",
      "         6.5753e+00,  2.0049e+00,  1.6267e+00, -1.0727e+00, -7.7402e-01,\n",
      "         2.2639e+00,  2.5466e+00, -4.6772e-01,  1.6248e+00,  5.2628e+00,\n",
      "        -6.6048e-01,  1.1023e+00,  3.5487e+00, -2.4491e+00, -5.9838e-01,\n",
      "         1.4851e+00, -7.3278e-01, -3.2659e-02,  3.0912e+00, -1.3538e+00,\n",
      "         1.0446e+00,  2.0119e-01,  1.0831e+00, -1.3379e+00,  2.0875e+00,\n",
      "        -1.4408e+00,  5.7531e-01,  2.7582e+00, -4.0145e-01,  6.4031e-01,\n",
      "         4.6663e-01,  3.1690e+00,  1.5221e-02, -1.3243e+00, -2.1554e+00,\n",
      "         4.1006e-01,  1.6371e+00,  1.6894e+00,  5.4853e+00,  4.2212e+00,\n",
      "        -1.4032e+00, -2.1492e+00,  4.7579e+00,  3.2655e+00,  1.6507e+00,\n",
      "         5.3572e+00,  1.3478e+00,  1.5682e-01, -3.5774e-01,  1.8522e+00,\n",
      "         2.5414e+00,  3.4862e+00, -1.7844e+00, -1.8350e-01, -4.9348e-01,\n",
      "        -1.5641e+00,  5.1891e+00,  2.2614e+00, -5.3629e-01, -1.5953e+00,\n",
      "         2.6662e+00,  4.1069e+00, -1.8144e+00, -2.4127e+00,  1.8961e+00,\n",
      "         2.2702e+00,  2.7167e+00,  1.4962e+00, -6.5074e-01,  1.0523e+00,\n",
      "        -1.1811e+00, -2.7409e+00, -5.6695e-02,  1.3119e+00,  1.4327e+00,\n",
      "         5.2379e+00,  3.6457e+00,  1.2545e+01,  1.7016e-01,  7.0745e+00,\n",
      "         1.0616e+00, -5.4612e-01, -3.1065e+00, -1.4075e+00,  2.4675e+00,\n",
      "         3.5093e+00, -2.2706e+00,  4.1640e+00,  1.2382e+00, -2.0416e+00,\n",
      "         3.7200e+00,  2.0222e-01, -5.1194e-02,  1.7210e+00,  2.4031e+00,\n",
      "        -1.8743e+00,  3.4529e+00, -7.5351e-01, -5.1582e-01, -2.9509e+00,\n",
      "        -1.7147e+00,  1.3831e+00,  2.9960e+00,  1.8907e+00,  1.8009e+00,\n",
      "        -6.7463e-01, -1.8022e+00, -3.5614e-01,  4.3332e-01,  2.0852e+00,\n",
      "         1.9384e+00,  5.6411e+00,  2.2407e+00,  2.4864e+00,  3.3805e+00,\n",
      "        -2.1816e+00, -5.8968e-02,  1.8770e+00, -9.5296e-02,  1.0443e+00,\n",
      "         2.5725e+00,  1.4503e+00, -2.0994e+00,  1.1648e+00,  1.5218e+00,\n",
      "         5.4955e-01,  1.0164e+00, -2.1489e+00,  1.7686e+00,  5.2876e-01,\n",
      "        -4.4866e-01, -1.5854e+00,  2.7281e+00,  3.0176e-01,  4.6774e+00,\n",
      "         1.0542e+00,  1.6128e+00,  4.4597e+00,  2.1565e+00,  2.9338e+00,\n",
      "         7.8339e-01,  1.5931e+00,  2.7445e+00,  1.8174e+00, -1.6940e+00,\n",
      "        -2.1141e-01, -5.7888e-01,  4.7457e-01,  4.7926e+00,  4.1464e+00,\n",
      "         4.8912e-03,  3.7330e-01,  5.6792e+00, -2.5926e+00, -1.6355e-01,\n",
      "        -1.0803e-01, -1.6430e+00,  1.0075e+00,  1.8201e+00, -1.2133e+00,\n",
      "         1.1035e+00,  1.0234e+00, -7.0476e-01,  1.3831e+00, -1.2352e+00,\n",
      "        -1.9822e+00,  6.8002e-01, -9.7723e-01, -1.8769e+00,  3.5826e+00,\n",
      "         5.8279e-01, -1.8538e+00,  3.9269e+00,  2.2540e+00,  3.2698e+00,\n",
      "         2.3203e+00, -1.0072e+00,  3.0992e+00,  2.7006e+00,  2.2362e-02,\n",
      "        -4.0728e-01,  7.4715e-01,  6.3895e-02,  2.6913e+00, -5.9830e-01,\n",
      "         6.1422e-01,  1.0696e+00,  5.0434e+00,  2.4403e+00, -1.0451e+00,\n",
      "        -3.5189e+00,  5.1331e+00,  1.3376e+00,  2.5807e+00, -1.4792e+00,\n",
      "         1.8723e-01, -4.0942e-01, -2.9677e+00, -5.4907e-01, -4.5234e-01,\n",
      "         2.8322e+00,  2.9248e+00,  2.1926e+00,  1.1125e+00, -2.4642e+00,\n",
      "         2.4018e-01, -5.9187e-02,  1.9933e+00, -1.6128e+00,  2.8142e+00,\n",
      "         3.9412e+00,  2.1468e+00, -2.1240e-01,  1.8900e+00,  1.1407e-02,\n",
      "        -9.7142e-01,  3.8374e-01,  3.4927e+00, -3.2545e+00,  1.4542e+00,\n",
      "         4.7545e+00, -1.3360e+00, -1.7025e+00,  1.3075e-01,  2.3842e+00,\n",
      "         6.4590e-01,  2.4089e+00,  3.1490e+00, -1.6384e+00, -1.5253e+00,\n",
      "        -2.3222e+00,  7.2118e-01, -5.6302e-01,  4.9248e+00, -9.4875e-01,\n",
      "         1.8288e+00, -1.5653e+00,  3.2826e-01,  3.0492e-01, -1.7614e+00,\n",
      "         2.6270e+00,  5.9214e-01, -2.4304e+00,  3.5402e+00,  6.6048e-01,\n",
      "         3.9962e+00, -1.8411e-01, -1.2575e+00,  5.0571e+00,  1.2017e-01,\n",
      "         1.7958e+00,  2.1867e+00,  3.9413e-02,  8.2089e-01,  7.3875e-01,\n",
      "        -8.9158e-01,  2.6623e+00,  6.3108e+00,  2.9358e+00, -2.9122e-01,\n",
      "         1.2459e+00,  3.5950e+00,  2.4664e+00,  5.1641e+00,  4.1635e+00,\n",
      "        -3.7509e-01,  3.8193e+00,  5.2402e+00,  5.9847e-02,  5.2781e-02,\n",
      "        -1.4630e+00, -5.1121e-02,  1.9323e+00,  1.1510e+00,  3.9344e-01,\n",
      "         1.2813e+00, -1.5582e+00, -1.3660e+00,  1.1105e+00, -2.4796e-01,\n",
      "        -2.6881e+00, -2.8391e-02,  1.3018e+00, -1.0512e+00,  5.0460e-01,\n",
      "         1.4793e+00,  2.6838e+00, -9.4505e-01,  1.8698e+00,  1.4044e+00,\n",
      "         2.7084e+00,  3.5705e-01,  7.0856e-01,  1.0985e-01,  2.2492e+00,\n",
      "         1.0898e+00, -5.4536e-01, -1.0735e-01, -2.7925e+00,  2.4015e-01,\n",
      "        -3.8022e-01,  2.3473e-01,  4.0437e-01, -3.8746e-01, -1.9989e+00,\n",
      "         4.8918e-01, -1.7142e+00, -1.5454e-01,  8.6810e-01, -1.7394e+00,\n",
      "        -1.1134e+00, -2.7940e+00, -1.8825e+00,  3.6806e+00,  1.3988e+00,\n",
      "         3.3735e+00,  3.9213e+00,  1.2883e+00, -5.5813e-01,  1.6095e+00,\n",
      "        -1.7722e+00, -5.9837e-01,  1.0552e+00, -1.0629e-01, -1.7743e+00,\n",
      "         1.7938e+00, -1.6106e-02, -1.0654e+00, -1.7205e+00,  8.8057e-01,\n",
      "         1.1790e-01,  3.2773e+00,  1.1270e+00,  3.1704e+00,  1.6333e+00,\n",
      "         1.6337e+00,  9.0143e+00, -1.4516e+00, -3.9257e-01, -1.6211e+00,\n",
      "        -1.2936e+00, -5.6661e-01,  9.1130e-01,  1.3202e+00, -1.7005e+00,\n",
      "         1.3182e+00, -9.5682e-01, -1.9122e+00,  1.5751e+00, -1.0045e+00,\n",
      "        -1.2750e+00, -1.9263e+00,  1.2252e+00, -4.5631e-01, -8.7240e-01,\n",
      "        -6.7834e-01, -1.8093e+00, -2.8726e+00, -9.0426e-01,  7.7514e-01,\n",
      "        -9.2928e-02,  1.4003e-02, -3.4509e-01,  5.3725e-01,  8.2447e-01])}\n"
     ]
    }
   ],
   "source": [
    "print(feature_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39d75037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "print(feature_list[0]['fc'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10738780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3006\n",
      "(1000,)\n",
      "(3006, 1000)\n"
     ]
    }
   ],
   "source": [
    "fc_list = []\n",
    "for i in range(len(feature_list)):\n",
    "    fc_list.append(feature_list[i]['fc'].numpy())\n",
    "\n",
    "\n",
    "print(len(fc_list))\n",
    "print(fc_list[0].shape)\n",
    "\n",
    "X = np.stack([f for f in fc_list], axis=0)\n",
    "\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0e4d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given that feature list is a list of dicts with dict_keys(['file_path', 'class', 'cm', 'hog', 'avgpool', 'layer3', 'fc'])\n",
    "# Convert it into a pandas dataframe\n",
    "df = pd.DataFrame(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68b69627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>class</th>\n",
       "      <th>cm</th>\n",
       "      <th>hog</th>\n",
       "      <th>avgpool</th>\n",
       "      <th>layer3</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>brain_glioma</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.8356), tensor(0.1613), tensor(0.5870...</td>\n",
       "      <td>[tensor(0.1084), tensor(0.0177), tensor(0.0076...</td>\n",
       "      <td>[tensor(-0.1851), tensor(2.3174), tensor(-0.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>brain_glioma</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.4021), tensor(0.1057), tensor(0.3497...</td>\n",
       "      <td>[tensor(0.1296), tensor(0.0262), tensor(0.0140...</td>\n",
       "      <td>[tensor(-0.4316), tensor(0.8583), tensor(-1.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>brain_glioma</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.5315), tensor(0.0803), tensor(0.2933...</td>\n",
       "      <td>[tensor(0.1146), tensor(0.0129), tensor(0.0106...</td>\n",
       "      <td>[tensor(-1.0882), tensor(1.2385), tensor(-1.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>brain_glioma</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(1....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.3852), tensor(0.2432), tensor(0.4104...</td>\n",
       "      <td>[tensor(0.1011), tensor(0.0200), tensor(0.0136...</td>\n",
       "      <td>[tensor(-1.1115), tensor(0.7664), tensor(-1.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>brain_glioma</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.5562), tensor(0.0179), tensor(0.5070...</td>\n",
       "      <td>[tensor(0.1269), tensor(0.0230), tensor(0.0161...</td>\n",
       "      <td>[tensor(-0.2769), tensor(0.6544), tensor(-1.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path         class  \\\n",
       "0  /workspaces/dbm25/data/Part1/Part1/brain_gliom...  brain_glioma   \n",
       "1  /workspaces/dbm25/data/Part1/Part1/brain_gliom...  brain_glioma   \n",
       "2  /workspaces/dbm25/data/Part1/Part1/brain_gliom...  brain_glioma   \n",
       "3  /workspaces/dbm25/data/Part1/Part1/brain_gliom...  brain_glioma   \n",
       "4  /workspaces/dbm25/data/Part1/Part1/brain_gliom...  brain_glioma   \n",
       "\n",
       "                                                  cm  \\\n",
       "0  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "1  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "2  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "3  [tensor(0.), tensor(0.), tensor(0.), tensor(1....   \n",
       "4  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "\n",
       "                                                 hog  \\\n",
       "0  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "1  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "2  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "3  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "4  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "\n",
       "                                             avgpool  \\\n",
       "0  [tensor(0.8356), tensor(0.1613), tensor(0.5870...   \n",
       "1  [tensor(0.4021), tensor(0.1057), tensor(0.3497...   \n",
       "2  [tensor(0.5315), tensor(0.0803), tensor(0.2933...   \n",
       "3  [tensor(0.3852), tensor(0.2432), tensor(0.4104...   \n",
       "4  [tensor(0.5562), tensor(0.0179), tensor(0.5070...   \n",
       "\n",
       "                                              layer3  \\\n",
       "0  [tensor(0.1084), tensor(0.0177), tensor(0.0076...   \n",
       "1  [tensor(0.1296), tensor(0.0262), tensor(0.0140...   \n",
       "2  [tensor(0.1146), tensor(0.0129), tensor(0.0106...   \n",
       "3  [tensor(0.1011), tensor(0.0200), tensor(0.0136...   \n",
       "4  [tensor(0.1269), tensor(0.0230), tensor(0.0161...   \n",
       "\n",
       "                                                  fc  \n",
       "0  [tensor(-0.1851), tensor(2.3174), tensor(-0.96...  \n",
       "1  [tensor(-0.4316), tensor(0.8583), tensor(-1.41...  \n",
       "2  [tensor(-1.0882), tensor(1.2385), tensor(-1.31...  \n",
       "3  [tensor(-1.1115), tensor(0.7664), tensor(-1.43...  \n",
       "4  [tensor(-0.2769), tensor(0.6544), tensor(-1.03...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba73ccbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['brain_glioma' 'brain_tumor' 'brain_menin']\n"
     ]
    }
   ],
   "source": [
    "# Show unique possible classes\n",
    "unique_classes = df['class'].unique()\n",
    "print(unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be48918c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>class</th>\n",
       "      <th>cm</th>\n",
       "      <th>hog</th>\n",
       "      <th>avgpool</th>\n",
       "      <th>layer3</th>\n",
       "      <th>fc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.8356), tensor(0.1613), tensor(0.5870...</td>\n",
       "      <td>[tensor(0.1084), tensor(0.0177), tensor(0.0076...</td>\n",
       "      <td>[tensor(-0.1851), tensor(2.3174), tensor(-0.96...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.4021), tensor(0.1057), tensor(0.3497...</td>\n",
       "      <td>[tensor(0.1296), tensor(0.0262), tensor(0.0140...</td>\n",
       "      <td>[tensor(-0.4316), tensor(0.8583), tensor(-1.41...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.5315), tensor(0.0803), tensor(0.2933...</td>\n",
       "      <td>[tensor(0.1146), tensor(0.0129), tensor(0.0106...</td>\n",
       "      <td>[tensor(-1.0882), tensor(1.2385), tensor(-1.31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(1....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.3852), tensor(0.2432), tensor(0.4104...</td>\n",
       "      <td>[tensor(0.1011), tensor(0.0200), tensor(0.0136...</td>\n",
       "      <td>[tensor(-1.1115), tensor(0.7664), tensor(-1.43...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/workspaces/dbm25/data/Part1/Part1/brain_gliom...</td>\n",
       "      <td>0</td>\n",
       "      <td>[tensor(0.), tensor(0.), tensor(0.), tensor(0....</td>\n",
       "      <td>[tensor(0., dtype=torch.float64), tensor(0., d...</td>\n",
       "      <td>[tensor(0.5562), tensor(0.0179), tensor(0.5070...</td>\n",
       "      <td>[tensor(0.1269), tensor(0.0230), tensor(0.0161...</td>\n",
       "      <td>[tensor(-0.2769), tensor(0.6544), tensor(-1.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_path  class  \\\n",
       "0  /workspaces/dbm25/data/Part1/Part1/brain_gliom...      0   \n",
       "1  /workspaces/dbm25/data/Part1/Part1/brain_gliom...      0   \n",
       "2  /workspaces/dbm25/data/Part1/Part1/brain_gliom...      0   \n",
       "3  /workspaces/dbm25/data/Part1/Part1/brain_gliom...      0   \n",
       "4  /workspaces/dbm25/data/Part1/Part1/brain_gliom...      0   \n",
       "\n",
       "                                                  cm  \\\n",
       "0  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "1  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "2  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "3  [tensor(0.), tensor(0.), tensor(0.), tensor(1....   \n",
       "4  [tensor(0.), tensor(0.), tensor(0.), tensor(0....   \n",
       "\n",
       "                                                 hog  \\\n",
       "0  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "1  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "2  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "3  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "4  [tensor(0., dtype=torch.float64), tensor(0., d...   \n",
       "\n",
       "                                             avgpool  \\\n",
       "0  [tensor(0.8356), tensor(0.1613), tensor(0.5870...   \n",
       "1  [tensor(0.4021), tensor(0.1057), tensor(0.3497...   \n",
       "2  [tensor(0.5315), tensor(0.0803), tensor(0.2933...   \n",
       "3  [tensor(0.3852), tensor(0.2432), tensor(0.4104...   \n",
       "4  [tensor(0.5562), tensor(0.0179), tensor(0.5070...   \n",
       "\n",
       "                                              layer3  \\\n",
       "0  [tensor(0.1084), tensor(0.0177), tensor(0.0076...   \n",
       "1  [tensor(0.1296), tensor(0.0262), tensor(0.0140...   \n",
       "2  [tensor(0.1146), tensor(0.0129), tensor(0.0106...   \n",
       "3  [tensor(0.1011), tensor(0.0200), tensor(0.0136...   \n",
       "4  [tensor(0.1269), tensor(0.0230), tensor(0.0161...   \n",
       "\n",
       "                                                  fc  \n",
       "0  [tensor(-0.1851), tensor(2.3174), tensor(-0.96...  \n",
       "1  [tensor(-0.4316), tensor(0.8583), tensor(-1.41...  \n",
       "2  [tensor(-1.0882), tensor(1.2385), tensor(-1.31...  \n",
       "3  [tensor(-1.1115), tensor(0.7664), tensor(-1.43...  \n",
       "4  [tensor(-0.2769), tensor(0.6544), tensor(-1.03...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique classes are ['brain_glioma' 'brain_tumor' 'brain_menin'] map them to 0, 1, 2\n",
    "class_mapping = {\n",
    "    'brain_glioma': 0,\n",
    "    'brain_tumor': 1,\n",
    "    'brain_menin': 2\n",
    "}\n",
    "# Map the dataframe class column to the new mapping\n",
    "df['class'] = df['class'].map(class_mapping)\n",
    "# Show the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3da3fd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â”€â”€ 1) Suppose df is your DataFrame\n",
    "# It has 3006 rows and df['fc'] is a torch.Tensor of shape (1000,)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "# Convert the column of tensors into an (N, 1000) NumPy array\n",
    "# (make sure each tensor is on CPU first)\n",
    "fc_arrays = np.stack([\n",
    "    t.cpu().numpy()\n",
    "    for t in df['layer3'].tolist()\n",
    "])  # shape: (3006, 1000)\n",
    "\n",
    "# â”€â”€ 2) Run KMeans\n",
    "# Pick the number of clusters you want, e.g. k = 5\n",
    "k = 3\n",
    "km = KMeans(n_clusters=k, random_state=0)\n",
    "km.fit(fc_arrays)\n",
    "\n",
    "# km.cluster_centers_  â†’ shape (k, 1000)\n",
    "# km.labels_           â†’ array of length 3006\n",
    "centroids = km.cluster_centers_\n",
    "labels = km.labels_\n",
    "\n",
    "# â”€â”€ 3) Add the labels back to your DataFrame\n",
    "df['cluster'] = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5933fe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster    0    1    2\n",
      "class                 \n",
      "0         11  460  531\n",
      "1        851   11  140\n",
      "2        218  216  568\n"
     ]
    }
   ],
   "source": [
    "# Check how many of each class are in each cluster\n",
    "cluster_counts = df.groupby(['class', 'cluster']).size().unstack(fill_value=0)\n",
    "print(cluster_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "527534ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /workspaces/dbm25/data/Part2/Part2/brain_glioma/brain_glioma_1009.jpg\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Sample image path\n",
    "sample_image_path = '/workspaces/dbm25/data/Part2/Part2/brain_glioma/brain_glioma_1009.jpg'\n",
    "\n",
    "test_features = extract_features(sample_image_path, model)\n",
    "# Check in which cluster the test image is\n",
    "test_features_layer3 = test_features['layer3'].cpu().numpy()\n",
    "# fit the test features to the kmeans model\n",
    "test_label = km.predict(test_features_layer3.reshape(1, -1))\n",
    "print(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402aae65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Check in which cluster the test image is\n",
    "test_features_layer3 = test_features['layer3'].cpu().numpy()\n",
    "# fit the test features to the kmeans model\n",
    "test_label = km.predict(test_features_layer3.reshape(1, -1))\n",
    "print(test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36572b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_class_list = []\n",
    "for i in range(len(feature_list)):\n",
    "    fc_class_list.append(feature_list[i]['class'].numpy())\n",
    "    fc_class_list.append(feature_list[i]['fc'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1f10cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1000)\n",
      "(3006,)\n",
      "[1 1 1 ... 2 1 1]\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "\n",
    "centroids = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO Add scikit learn rand_score "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
