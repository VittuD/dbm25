{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f302d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import grayscale_moments\n",
    "import resnet\n",
    "import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c1aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_path = '../data/Part1/Part1'\n",
    "data2_path = '../data/Part2/Part2'\n",
    "\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72506612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to store the results\n",
    "extracted_features = {\n",
    "    'file_path': [],\n",
    "    'class': [],\n",
    "    'cm': [],\n",
    "    'hog': [],\n",
    "    'avgpool': [],\n",
    "    'layer3': [],\n",
    "    'fc': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a55f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_features = []\n",
    "# For each image in data1_path extract the features\n",
    "for root, dirs, files in os.walk(data1_path):\n",
    "    for image in files:\n",
    "        if not image.endswith('.jpg'):\n",
    "            continue\n",
    "\n",
    "        # Class can be glioma, menin, tumor. Get the class from the filename\n",
    "        class_name = image.split('_')[0]+'_' + image.split('_')[1]\n",
    "        image_path = os.path.join(f'{class_name}/', image)\n",
    "        # Get the full path to the image\n",
    "        image_path = os.path.abspath(os.path.join(data1_path, image_path))\n",
    "        print(f'Processing {image_path}')\n",
    "\n",
    "        # Load the image\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        grayscale_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        blocks = grayscale_moments.blockify(grayscale_img, new_H=300, new_W=100, block_H=30, block_W=10)\n",
    "\n",
    "        # For each block, calculate the color moments, return a tensor of shape [(3*blocks)]\n",
    "        color_moments = []\n",
    "        for block in blocks:\n",
    "            moments = grayscale_moments.moments(block.numpy())\n",
    "            color_moments.extend(moments)  # Append the moments directly to the list\n",
    "        color_moments = torch.tensor(color_moments)  # Convert the list to a tensor\n",
    "\n",
    "        print(f'Color moments: {color_moments.shape}')\n",
    "\n",
    "        hog_features = hog.hog(grayscale_img)\n",
    "\n",
    "        preprocessed_img = resnet.preprocess_image(img)\n",
    "\n",
    "        resnet_features = resnet.extract_layer_features(model, preprocessed_img, layer_names=['avgpool', 'layer3', 'fc'])\n",
    "        avgpool = resnet_features['avgpool']\n",
    "        layer3 = resnet_features['layer3']\n",
    "        fc = resnet_features['fc']\n",
    "        avgpool = avgpool.view(avgpool.size(1))\n",
    "        avgpool = torch.mean(avgpool.view(-1, 2), dim=1)\n",
    "        layer3 = torch.mean(layer3.view(-1, 1024, 14*14), dim=2)\n",
    "        layer3 = layer3.view(layer3.size(1))\n",
    "        fc = fc.view(fc.size(1))\n",
    "        \n",
    "        features_dict = {\n",
    "            'file_path': image_path,\n",
    "            'class': class_name,\n",
    "            'cm': color_moments,\n",
    "            'hog': hog_features,\n",
    "            'avgpool': avgpool,\n",
    "            'layer3': layer3,\n",
    "            'fc': fc\n",
    "        }\n",
    "        # Append the features to the list\n",
    "        extracted_features.append(features_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffe2211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the extracted features into a pt file\n",
    "torch.save(extracted_features, '../data/extracted_features.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1dcbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the extracted features from the pt file\n",
    "extracted_features = torch.load('../data/extracted_features.pt')\n",
    "# Print the extracted features\n",
    "print(extracted_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
