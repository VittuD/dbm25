{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f822e7a-2d71-452a-89fe-b181bbdf2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44965b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1_path = 'data/Part1/Part1'\n",
    "data2_path = 'data/Part2/Part2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbb1ec28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the pretrained ResNet-50 model from torchvision\n",
    "# and load it into the model.\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aee749c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the image\n",
    "def resnet_preprocessor(image):\n",
    "    # Resize the image to 224x224\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # Convert the image to a tensor\n",
    "    image = torch.tensor(image).permute(2, 0, 1).float()\n",
    "    # Normalize the image\n",
    "    image = (image - 127.5) / 127.5\n",
    "    # Add a batch dimension\n",
    "    image = image.unsqueeze(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "449f66e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_layer_features(\n",
    "    model: torch.nn.Module,\n",
    "    x: torch.Tensor,\n",
    "    layer_name: str\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Run x through model, grab the output of a specified layer via forward hook,\n",
    "    then remove the hook and return the raw feature tensor.\n",
    "\n",
    "    Args:\n",
    "        model:        A PyTorch model (e.g. torchvision.models.resnet50(pretrained=True))\n",
    "        x:            Input tensor of shape [B, C, H, W] (already preprocessed)\n",
    "        layer_name:   Dot-separated layer name as in model.named_modules()\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Output of the specified layer\n",
    "    \"\"\"\n",
    "    # Store hooked output\n",
    "    features = {}\n",
    "\n",
    "    def _hook(module, inp, out):\n",
    "        # Detach and store output\n",
    "        features['feat'] = out.detach()\n",
    "\n",
    "    # Find modules by name\n",
    "    modules = dict(model.named_modules())\n",
    "    if layer_name not in modules:\n",
    "        raise ValueError(f\"Layer '{layer_name}' not found in model.\")\n",
    "    \n",
    "    # Register hook\n",
    "    handle = modules[layer_name].register_forward_hook(_hook)\n",
    "\n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        _ = model(x)\n",
    "\n",
    "    # Remove hook\n",
    "    handle.remove()\n",
    "\n",
    "    # Return raw features\n",
    "    return features.get('feat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20c411e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 714\n"
     ]
    }
   ],
   "source": [
    "# Open image using OpenCV from data/Part1/Part1/brain_glioma/brain_glioma_0001.jpg\n",
    "image = cv2.imread(f'{data1_path}/brain_glioma/brain_glioma_0001.jpg')\n",
    "# Pass the image through the model and print the classification\n",
    "image = resnet_preprocessor(image)\n",
    "# Pass the image through the model\n",
    "with torch.no_grad():  # Disable gradient calculation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    output = model(image)  # Forward pass\n",
    "# Get the predicted class\n",
    "_, predicted = torch.max(output, 1)\n",
    "# Print the predicted class\n",
    "print(f'Predicted class: {predicted.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d4a1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([1, 2048, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Open image using OpenCV from data/Part1/Part1/brain_glioma/brain_glioma_0001.jpg\n",
    "image = cv2.imread(f'{data1_path}/brain_glioma/brain_glioma_0001.jpg')\n",
    "# Pass the image through the model and print the classification\n",
    "image = resnet_preprocessor(image)\n",
    "# Extract features from the 'avgpool' layer\n",
    "features = extract_layer_features(model, image, 'avgpool')\n",
    "# Print the shape of the features\n",
    "print(f'Features shape: {features.shape}')  # e.g. torch.Size([1, 2048, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b936e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([1, 1024, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "# Open image using OpenCV from data/Part1/Part1/brain_glioma/brain_glioma_0001.jpg\n",
    "image = cv2.imread(f'{data1_path}/brain_glioma/brain_glioma_0001.jpg')\n",
    "# Pass the image through the model and print the classification\n",
    "image = resnet_preprocessor(image)\n",
    "# Extract features from the 'avgpool' layer\n",
    "features = extract_layer_features(model, image, 'layer3')\n",
    "# Print the shape of the features\n",
    "print(f'Features shape: {features.shape}')  # e.g. torch.Size([1, 2048, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9dfb86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Open image using OpenCV from data/Part1/Part1/brain_glioma/brain_glioma_0001.jpg\n",
    "image = cv2.imread(f'{data1_path}/brain_glioma/brain_glioma_0001.jpg')\n",
    "# Pass the image through the model and print the classification\n",
    "image = resnet_preprocessor(image)\n",
    "# Extract features from the 'avgpool' layer\n",
    "features = extract_layer_features(model, image, 'fc')\n",
    "# Print the shape of the features\n",
    "print(f'Features shape: {features.shape}')  # e.g. torch.Size([1, 2048, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62d54969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (10, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZgAAAGdCAYAAAAv9mXmAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFFdJREFUeJzt3X9sVfX9+PFXKVKqaRvFgRJA0SxTAX8WjJI4F4nGqJnL4rYEE4P/LVVAkkWYccSgVLbMkIhjYhZ1maBbNqYz08XUCGNKQFCn2SZuxq3RAJqYexGzatrz+WPf9Pvhc5X1Yl8998Ljkbz/6Mk5Pa8coM+ce8q9LUVRFAEAo2xc2QMAcHQSGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEgxfqxPODQ0FO+99150dHRES0vLWJ8egC+gKIo4cOBATJ06NcaNO/w9ypgH5r333ovp06eP9WkBGEX9/f0xbdq0w+4z5i+RdXR0jPUpARhlI/lZPuaB8bIYQPMbyc9yD/kBSCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUhxRYB544IE4/fTTY+LEiXHxxRfHjh07RnsuAJpc3YF54oknYtmyZbFy5crYvXt3nHfeeXHVVVfF/v37M+YDoFkVdZo3b17R09Mz/PXg4GAxderUore3d0THVyqVIiIsy7KsJl6VSuW//ryv6w7mk08+iV27dsWCBQuGt40bNy4WLFgQL7300mceMzAwENVq9ZAFwNGvrsB88MEHMTg4GFOmTDlk+5QpU2Lv3r2feUxvb290dXUNL59mCXBsSP8tshUrVkSlUhle/f392acEoAGMr2fnk08+OVpbW2Pfvn2HbN+3b1+ccsopn3lMW1tbtLW1HfmEADSluu5gJkyYEBdddFH09fUNbxsaGoq+vr645JJLRn04AJpXXXcwERHLli2Lm266Kbq7u2PevHmxdu3aOHjwYCxatChjPgCaVN2B+fa3vx3vv/9+/OAHP4i9e/fG+eefH88++2zNg38Ajm0tRVEUY3nCarUaXV1dY3lKAEZZpVKJzs7Ow+7jvcgASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUtT9ZpfQaH7729+WPUKNwcHBskeo8c4775Q9Qo1t27aVPUKNzZs3lz3CUcMdDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEgRUtRFMVYnrBarUZXV9dYnpJR9Ktf/arsEWq88847ZY9Q4/nnny97hBq///3vyx6hRktLS9kj1FixYkXZI9T40Y9+VPYIw4qiiMHBwahUKtHZ2XnYfd3BAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBR1Baa3tzfmzp0bHR0dMXny5Lj++uvjzTffzJoNgCZWV2C2bNkSPT09sX379njuuefi008/jSuvvDIOHjyYNR8ATWp8PTs/++yzh3z9yCOPxOTJk2PXrl1x2WWXjepgADS3ugLzf1UqlYiIOOmkkz53n4GBgRgYGBj+ulqtfpFTAtAkjvgh/9DQUCxdujTmz58fs2fP/tz9ent7o6ura3hNnz79SE8JQBM54sD09PTEG2+8EY8//vhh91uxYkVUKpXh1d/ff6SnBKCJHNFLZLfccks8/fTTsXXr1pg2bdph921ra4u2trYjGg6A5lVXYIqiiFtvvTU2b94cL7zwQsycOTNrLgCaXF2B6enpiY0bN8aTTz4ZHR0dsXfv3oiI6Orqivb29pQBAWhOdT2DWb9+fVQqlbj88svj1FNPHV5PPPFE1nwANKm6XyIDgJHwXmQApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKb7QRyZz7Onr6yt7hBqN+E7ep512Wtkj1GhtbS17hBpbtmwpe4Qa9957b9kj1GikP7uiKGJwcHBE+7qDASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkaCmKohjLE1ar1ejq6hrLUzKKvvGNb5Q9Qo2TTz657BFqvPXWW2WPUOO4444re4QaEydOLHuEGv/4xz/KHqHGgQMHyh5h2NDQULz77rtRqVSis7PzsPu6gwEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApvlBg7r333mhpaYmlS5eO0jgAHC2OODA7d+6MBx98MM4999zRnAeAo8QRBeajjz6KhQsXxkMPPRQnnnjiaM8EwFHgiALT09MT11xzTSxYsOC/7jswMBDVavWQBcDRb3y9Bzz++OOxe/fu2Llz54j27+3tjbvuuqvuwQBobnXdwfT398eSJUviscceG/Fnaa9YsSIqlcrw6u/vP6JBAWgudd3B7Nq1K/bv3x8XXnjh8LbBwcHYunVrrFu3LgYGBqK1tfWQY9ra2qKtrW10pgWgadQVmCuuuCJef/31Q7YtWrQozjrrrLj99ttr4gLAsauuwHR0dMTs2bMP2XbCCSfEpEmTarYDcGzzP/kBSFH3b5H9Xy+88MIojAHA0cYdDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0CKL/xeZBxbjj/++LJHqPHOO++UPUKNRvzoiksuuaTsEWrcfffdZY9Q46OPPip7hBqN+O9uJNzBAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSjC97AJrLY489VvYINcaPb7y/xkNDQ2WPUOPyyy8ve4Qav/nNb8oeocbxxx9f9ghHDXcwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIEXdgXn33XfjxhtvjEmTJkV7e3vMmTMnXn755YzZAGhidX2Qxocffhjz58+Pr33ta/HMM8/El770pXjrrbfixBNPzJoPgCZVV2DWrFkT06dPj4cffnh428yZM0d9KACaX10vkT311FPR3d0dN9xwQ0yePDkuuOCCeOihhw57zMDAQFSr1UMWAEe/ugLz9ttvx/r16+PLX/5y/OEPf4jvfve7sXjx4nj00Uc/95je3t7o6uoaXtOnT//CQwPQ+FqKoihGuvOECROiu7s7XnzxxeFtixcvjp07d8ZLL730mccMDAzEwMDA8NfValVkGFXjx9f1Su+YGBoaKnuEGnfddVfZI9SYM2dO2SPUuP7668seoSlUKpXo7Ow87D513cGceuqpcc455xyy7eyzz45//etfn3tMW1tbdHZ2HrIAOPrVFZj58+fHm2++eci2PXv2xGmnnTaqQwHQ/OoKzG233Rbbt2+P1atXx9///vfYuHFjbNiwIXp6erLmA6BJ1RWYuXPnxubNm2PTpk0xe/bsWLVqVaxduzYWLlyYNR8ATarup6PXXnttXHvttRmzAHAU8V5kAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACnq+sCx0VCtVqOrq2ssTwnAKBv1DxwDgJESGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKeoKzODgYNx5550xc+bMaG9vjzPPPDNWrVoVRVFkzQdAkxpfz85r1qyJ9evXx6OPPhqzZs2Kl19+ORYtWhRdXV2xePHirBkBaEJ1BebFF1+Mr3/963HNNddERMTpp58emzZtih07dqQMB0DzquslsksvvTT6+vpiz549ERHx2muvxbZt2+Lqq6/+3GMGBgaiWq0esgA4BhR1GBwcLG6//faipaWlGD9+fNHS0lKsXr36sMesXLmyiAjLsizrKFqVSuW/NqOuwGzatKmYNm1asWnTpuLPf/5z8fOf/7w46aSTikceeeRzj/n3v/9dVCqV4dXf31/6hbEsy7K+2Br1wEybNq1Yt27dIdtWrVpVfOUrXxnx96hUKqVfGMuyLOuLrZEEpq5nMB9//HGMG3foIa2trTE0NFTPtwHgGFDXb5Fdd911cc8998SMGTNi1qxZ8corr8R9990XN998c9Z8ADSrel4iq1arxZIlS4oZM2YUEydOLM4444zijjvuKAYGBrxEZlmWdQytkbxE1lIUY/vf8KvVanR1dY3lKQEYZZVKJTo7Ow+7j/ciAyCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFAIDQAqBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEghMACkEBgAUggMACkEBoAUAgNACoEBIIXAAJBCYABIITAApBAYAFIIDAApBAaAFGMemKIoxvqUAIyykfwsH/PAHDhwYKxPCcAoG8nP8pZijG8phoaG4r333ouOjo5oaWk54u9TrVZj+vTp0d/fH52dnaM44dHFdRoZ12lkXKeROZqvU1EUceDAgZg6dWqMG3f4e5TxYzTTsHHjxsW0adNG7ft1dnYedX+AGVynkXGdRsZ1Gpmj9Tp1dXWNaD8P+QFIITAApGjawLS1tcXKlSujra2t7FEamus0Mq7TyLhOI+M6/ceYP+QH4NjQtHcwADQ2gQEghcAAkEJgAEjRtIF54IEH4vTTT4+JEyfGxRdfHDt27Ch7pIbS29sbc+fOjY6Ojpg8eXJcf/318eabb5Y9VkO79957o6WlJZYuXVr2KA3n3XffjRtvvDEmTZoU7e3tMWfOnHj55ZfLHquhDA4Oxp133hkzZ86M9vb2OPPMM2PVqlXH9PsvNmVgnnjiiVi2bFmsXLkydu/eHeedd15cddVVsX///rJHaxhbtmyJnp6e2L59ezz33HPx6aefxpVXXhkHDx4se7SGtHPnznjwwQfj3HPPLXuUhvPhhx/G/Pnz47jjjotnnnkm/vKXv8SPf/zjOPHEE8seraGsWbMm1q9fH+vWrYu//vWvsWbNmvjhD38Y999/f9mjlaYpf0354osvjrlz58a6desi4j/vbzZ9+vS49dZbY/ny5SVP15jef//9mDx5cmzZsiUuu+yyssdpKB999FFceOGF8ZOf/CTuvvvuOP/882Pt2rVlj9Uwli9fHn/605/ij3/8Y9mjNLRrr702pkyZEj/72c+Gt33zm9+M9vb2+MUvflHiZOVpujuYTz75JHbt2hULFiwY3jZu3LhYsGBBvPTSSyVO1tgqlUpERJx00kklT9J4enp64pprrjnk7xT/31NPPRXd3d1xww03xOTJk+OCCy6Ihx56qOyxGs6ll14afX19sWfPnoiIeO2112Lbtm1x9dVXlzxZecb8zS6/qA8++CAGBwdjypQph2yfMmVK/O1vfytpqsY2NDQUS5cujfnz58fs2bPLHqehPP7447F79+7YuXNn2aM0rLfffjvWr18fy5Yti+9///uxc+fOWLx4cUyYMCFuuummssdrGMuXL49qtRpnnXVWtLa2xuDgYNxzzz2xcOHCskcrTdMFhvr19PTEG2+8Edu2bSt7lIbS398fS5Ysieeeey4mTpxY9jgNa2hoKLq7u2P16tUREXHBBRfEG2+8ET/96U8F5n/55S9/GY899lhs3LgxZs2aFa+++mosXbo0pk6desxep6YLzMknnxytra2xb9++Q7bv27cvTjnllJKmaly33HJLPP3007F169ZR/ZiEo8GuXbti//79ceGFFw5vGxwcjK1bt8a6detiYGAgWltbS5ywMZx66qlxzjnnHLLt7LPPjl//+tclTdSYvve978Xy5cvjO9/5TkREzJkzJ/75z39Gb2/vMRuYpnsGM2HChLjooouir69veNvQ0FD09fXFJZdcUuJkjaUoirjlllti8+bN8fzzz8fMmTPLHqnhXHHFFfH666/Hq6++Ory6u7tj4cKF8eqrr4rL/zN//vyaX3Hfs2dPnHbaaSVN1Jg+/vjjmg/gam1tjaGhoZImKl/T3cFERCxbtixuuumm6O7ujnnz5sXatWvj4MGDsWjRorJHaxg9PT2xcePGePLJJ6OjoyP27t0bEf/5oKD29vaSp2sMHR0dNc+kTjjhhJg0aZJnVf/LbbfdFpdeemmsXr06vvWtb8WOHTtiw4YNsWHDhrJHayjXXXdd3HPPPTFjxoyYNWtWvPLKK3HffffFzTffXPZo5Sma1P3331/MmDGjmDBhQjFv3rxi+/btZY/UUCLiM9fDDz9c9mgN7atf/WqxZMmSssdoOL/73e+K2bNnF21tbcVZZ51VbNiwoeyRGk61Wi2WLFlSzJgxo5g4cWJxxhlnFHfccUcxMDBQ9milacr/BwNA42u6ZzAANAeBASCFwACQQmAASCEwAKQQGABSCAwAKQQGgBQCA0AKgQEghcAAkEJgAEjxP1YjLhEiGV1fAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open image using OpenCV from data/Part1/Part1/brain_glioma/brain_glioma_0001.jpg\n",
    "image = cv2.imread(f'{data1_path}/brain_glioma/brain_glioma_0001.jpg')\n",
    "image = image[:, :, 0]\n",
    "# Resize to 10*10\n",
    "image = cv2.resize(image, (10, 10))\n",
    "\n",
    "print(f'Image shape: {image.shape}')\n",
    "\n",
    "# Show image using matplotlib\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5151224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of blocks: 100\n",
      "Block shape: (30, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Open image using OpenCV from data/Part1/Part1/brain_glioma/brain_glioma_0001.jpg\n",
    "image = cv2.imread(f'{data1_path}/brain_glioma/brain_glioma_0002.jpg')\n",
    "# Convert to grayscale\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# Resize the image to 300x100\n",
    "image = cv2.resize(image, (300, 100))\n",
    "# Partition the image into 10*10 blocks\n",
    "blocks = []\n",
    "# Divide the image into non-overlapping 30*10 blocks\n",
    "for i in range(0, image.shape[0], 10):\n",
    "    for j in range(0, image.shape[1], 30):\n",
    "        block = image[i:i+10, j:j+30].T  # Transpose the block to get shape (30, 10)\n",
    "        blocks.append(block)\n",
    "\n",
    "print(f'Number of blocks: {len(blocks)}')\n",
    "print(f'Block shape: {blocks[70].shape}')\n",
    "\n",
    "# Show the 100th block using matplotlib\n",
    "plt.imshow(blocks[70], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4263717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_moments(image):\n",
    "    \"\"\"\n",
    "    Calculate the first 3 moments of the image, mean, variance, and skewness.\n",
    "\n",
    "    Args:\n",
    "        image: Input image\n",
    "\n",
    "    Returns:\n",
    "        Tuple: Moments of the image\n",
    "    \"\"\"\n",
    "    # Calculate the mean\n",
    "    mean = np.mean(image)\n",
    "    # Calculate the variance\n",
    "    variance = np.var(image)\n",
    "    # Calculate the skewness\n",
    "    skewness = np.mean((image - mean) ** 3) / (variance ** 1.5) if variance != 0 else 0\n",
    "    return np.array([mean, variance, skewness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc1ba317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "[ 10.70666667 200.75395556   0.73580681]\n"
     ]
    }
   ],
   "source": [
    "moments = []\n",
    "# Compute moments for all blocks\n",
    "for i, block in enumerate(blocks):\n",
    "    # Compute the moments of the block\n",
    "    block_moments = get_moments(block)\n",
    "    # Append the moments to the list\n",
    "    moments.append(block_moments)\n",
    "# Convert moments to a numpy array\n",
    "moments = np.array(moments)\n",
    "print(moments.shape)\n",
    "print(moments[70])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
